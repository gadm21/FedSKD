{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_MNIST_data, load_FEMNIST_data, load_EMNIST_data, generate_bal_private_data\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import errno\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "import json \n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_utils import load_MNIST_data, load_FEMNIST_data, load_EMNIST_data, generate_bal_private_data\n",
    "from data_utils import generate_partial_data, load_ready_data\n",
    "from FedMD import FedMD, FedAvg\n",
    "from FedSKD import FedSKD \n",
    "from Neural_Networks import train_models, cnn_2layer_fc_model, cnn_3layer_fc_model\n",
    "from utility import * \n",
    "\n",
    "import pandas as pd            # For data manipulation\n",
    "import seaborn as sns          # For plotting heatmap\n",
    "import matplotlib.pyplot as plt  # For visualization and saving the plot\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_dataset_name = 'MNIST' # 'CIFAR10', 'CIFAR100', 'FEMNIST', 'MNIST'\n",
    "\n",
    "\n",
    "\n",
    "if private_dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "    public_dataset_name = 'CIFAR10' if private_dataset_name == 'CIFAR100' else 'CIFAR100'\n",
    "else : \n",
    "    public_dataset_name = 'MNIST' if private_dataset_name == 'FEMNIST' else 'FEMNIST'\n",
    "\n",
    "print(\"private dataset: {0}\".format(private_dataset_name))\n",
    "print(\"public dataset: {0}\".format(public_dataset_name))\n",
    "\n",
    "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model, \n",
    "                    \"3_layer_CNN\": cnn_3layer_fc_model} \n",
    "\n",
    "\n",
    "if private_dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "    conf_file = os.path.abspath(\"../conf/CIFAR_balance_conf.json\")\n",
    "else : \n",
    "    conf_file = os.path.abspath(\"../conf/MNIST_balance_conf.json\")\n",
    "with open(conf_file, \"r\") as f:\n",
    "    conf_dict = json.load(f) \n",
    "    \n",
    "    #n_classes = conf_dict[\"n_classes\"]\n",
    "    model_config = conf_dict[\"models\"]\n",
    "    pre_train_params = conf_dict[\"pre_train_params\"]\n",
    "    model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
    "    model_saved_names = conf_dict[\"model_saved_names\"]\n",
    "    is_early_stopping = conf_dict[\"early_stopping\"]\n",
    "    public_classes = conf_dict[\"public_classes\"]\n",
    "    private_classes = conf_dict[\"private_classes\"]\n",
    "    n_classes = len(public_classes)\n",
    "    \n",
    "    \n",
    "    N_parties = conf_dict[\"N_parties\"]\n",
    "    N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
    "    \n",
    "    N_rounds = conf_dict[\"N_rounds\"]\n",
    "    N_alignment = conf_dict[\"N_alignment\"]\n",
    "    N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
    "    private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
    "    N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
    "    logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
    "    aug = conf_dict[\"aug\"]\n",
    "    compress = conf_dict[\"compress\"]\n",
    "    select = conf_dict[\"select\"]\n",
    "    algorithm = conf_dict[\"algorithm\"]\n",
    "    \n",
    "    dataset_dir = conf_dict[\"dataset_dir\"]\n",
    "    result_save_dir = conf_dict[\"result_save_dir\"]\n",
    "    \n",
    "    if algorithm == 'fedavg':\n",
    "        result_save_dir = result_save_dir + \"_fedavg\"\n",
    "    \n",
    "    elif algorithm == 'fedmd':\n",
    "        result_save_dir = result_save_dir + \"_fedmd\"\n",
    "\n",
    "    elif algorithm == 'fedskd':\n",
    "        result_save_dir = result_save_dir + \"_fedskd\"\n",
    "\n",
    "        if aug : \n",
    "            print(\"adding aug\")\n",
    "            result_save_dir = result_save_dir + \"_aug\"\n",
    "        if compress:\n",
    "            print(\"adding compress\")\n",
    "            result_save_dir = result_save_dir + \"_compress\"\n",
    "        if select:\n",
    "            print(\"adding select\")\n",
    "            result_save_dir = result_save_dir + \"_select\"\n",
    "            \n",
    "        print(\"Using {} alignment\".format(N_alignment))\n",
    "        result_save_dir = result_save_dir + \"_exp{}\".format(N_alignment)\n",
    "\n",
    "    if os.path.exists(result_save_dir):\n",
    "        result_save_dir = result_save_dir + \"_{}\".format(np.random.randint(1000))\n",
    "    os.makedirs(result_save_dir)\n",
    "\n",
    "\n",
    "del conf_dict, conf_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "def all_digit(x) : \n",
    "    return all([c.isdigit() for c in x])\n",
    "\n",
    "# resize image to shape \n",
    "def resize_this_image(x, shape, denormalize = True, normalize_back = True) : \n",
    "    if denormalize : \n",
    "        x = (x+0.5) * 255.0\n",
    "        x = x.astype(np.uint8)\n",
    "    y = np.array(Image.fromarray(x).resize(shape), dtype = np.float32) \n",
    "    if normalize_back : \n",
    "        y = y / 255.0 - 0.5\n",
    "    return y\n",
    "\n",
    "\n",
    "def resize_dataset(x, new_shape) : \n",
    "    num_images = len(x) \n",
    "    new_x = []\n",
    "    for image in range(num_images) : \n",
    "        new_x.append(resize_this_image(x[image, ...], new_shape))\n",
    "    new_x = np.array(new_x)\n",
    "    return new_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_X_train, private_y_train, private_X_test, private_y_test = load_FEMNIST_data(standarized=False, verbose = False) \n",
    "public_X_train, public_y_train, public_X_test, public_y_test = load_MNIST_data(standarized=False, verbose = False) \n",
    "\n",
    "private_classes = np.unique(private_y_train)\n",
    "n_private_classes = len(np.unique(private_y_train))\n",
    "\n",
    "\n",
    "private_data, total_private_data = generate_bal_private_data(private_X_train, private_y_train, N_parties, private_classes, N_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'fedskd'\n",
    "input_shape = private_X_train.shape[1:]\n",
    "parties = [] \n",
    "\n",
    "for i in range(N_parties) : \n",
    "    model_idx = i if algorithm != 'fedavg' else 0\n",
    "    item = model_config[model_idx] \n",
    "    model_name = item['model_type']\n",
    "    model_params = item['params']\n",
    "    model = CANDIDATE_MODELS[model_name](n_classes = n_private_classes,\n",
    "                                         input_shape = input_shape,\n",
    "                                         **model_params)\n",
    "    parties.append(model) \n",
    "\n",
    "\n",
    "len(parties) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretraining models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train all models on the public dataset\n",
    "results = train_models(parties, public_X_train, public_y_train, public_X_test, public_y_test, verbose = 0) \n",
    "\n",
    "print(\"public training results\")\n",
    "for res in results : \n",
    "    print(res) \n",
    "print()\n",
    "\n",
    "# Train each model on his private dataset \n",
    "for i, party in enumerate(parties) :\n",
    "    X_train, y_train = private_data[i]\n",
    "    X_test, y_test = total_private_data[i]\n",
    "    party.fit(X_train, y_train, private_X_test, private_y_test, epochs = pre_train_params['epochs'], batch_size = pre_train_params['batch_size'], verbose = 1)\n",
    "\n",
    "\n",
    "# Evaluate each model on his private dataset\n",
    "private_scores = []\n",
    "for i, party in enumerate(parties) :\n",
    "    score = party.evaluate(private_X_test, private_y_test, verbose = 0)\n",
    "    private_scores.append(score) \n",
    "    print(\"party {} : {}\".format(i, score))\n",
    "\n",
    "print(\"private training results\")\n",
    "for score in private_scores : \n",
    "    print(score) \n",
    "print() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run FedSKD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fedskd = FedSKD(parties, private_data, (private_X_test, private_y_test), N_rounds = N_rounds,\n",
    "                                    N_private_training_round = N_private_training_round,\n",
    "                                    private_training_batchsize = private_training_batchsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCIUJXV4mEXj",
        "outputId": "b29c8126-e1cd-445b-b6b3-b4cd06c54115"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/gadm21/FedSKD\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/content/FedSKD')\n",
        "# sys.path.append('/FedSKD/src')\n",
        "\n",
        "\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGufYZ0in_JC",
        "outputId": "6fcce357-786b-4681-947e-e30d69402792"
      },
      "outputs": [],
      "source": [
        "%cd FedSKD/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36nJTwsil5Rm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import errno\n",
        "import argparse\n",
        "import sys\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from data_utils import load_CIFAR10_data, load_CIFAR100_data, generate_partial_data, generate_bal_private_data, load_FEMNIST_data, load_MNIST_data, load_ready_data\n",
        "from FedMD import FedMD\n",
        "from Neural_Networks import train_models, cnn_2layer_fc_model, cnn_3layer_fc_model\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import clone_model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from utility import *\n",
        "from data_utils import generate_alignment_data\n",
        "from Neural_Networks import remove_last_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trBHlorKl5Rn"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMH0H0D-l5Rn",
        "outputId": "76bf34f2-da17-494f-ef9a-42a246bbdd8b"
      },
      "outputs": [],
      "source": [
        "private_dataset_name = 'CIFAR10' # 'CIFAR10', 'CIFAR100', 'FEMNIST', 'MNIST\n",
        "if private_dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "    public_dataset_name = 'CIFAR10' if private_dataset_name == 'CIFAR100' else 'CIFAR100'\n",
        "else :\n",
        "    public_dataset_name = 'MNIST' if private_dataset_name == 'FEMNIST' else 'FEMNIST'\n",
        "\n",
        "print(\"private dataset: {0}\".format(private_dataset_name))\n",
        "print(\"public dataset: {0}\".format(public_dataset_name))\n",
        "\n",
        "CANDIDATE_MODELS = {\"2_layer_CNN\": cnn_2layer_fc_model,\n",
        "                    \"3_layer_CNN\": cnn_3layer_fc_model}\n",
        "\n",
        "if private_dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
        "    conf_file = os.path.abspath(\"../conf/CIFAR_balance_conf.json\")\n",
        "else :\n",
        "    conf_file = os.path.abspath(\"../conf/EMNIST_balance_conf.json\")\n",
        "with open(conf_file, \"r\") as f:\n",
        "    conf_dict = json.load(f)\n",
        "\n",
        "    #n_classes = conf_dict[\"n_classes\"]\n",
        "    model_config = conf_dict[\"models\"]\n",
        "    pre_train_params = conf_dict[\"pre_train_params\"]\n",
        "    model_saved_dir = conf_dict[\"model_saved_dir\"]\n",
        "    model_saved_names = conf_dict[\"model_saved_names\"]\n",
        "    is_early_stopping = conf_dict[\"early_stopping\"]\n",
        "    public_classes = conf_dict[\"public_classes\"]\n",
        "    private_classes = conf_dict[\"private_classes\"]\n",
        "    n_classes = len(public_classes) + len(private_classes)\n",
        "\n",
        "    # emnist_data_dir = conf_dict[\"EMNIST_dir\"]\n",
        "    N_parties = conf_dict[\"N_parties\"]\n",
        "    N_samples_per_class = conf_dict[\"N_samples_per_class\"]\n",
        "\n",
        "    N_rounds = conf_dict[\"N_rounds\"]\n",
        "    N_alignment = conf_dict[\"N_alignment\"]\n",
        "    N_private_training_round = conf_dict[\"N_private_training_round\"]\n",
        "    private_training_batchsize = conf_dict[\"private_training_batchsize\"]\n",
        "    N_logits_matching_round = conf_dict[\"N_logits_matching_round\"]\n",
        "    logits_matching_batchsize = conf_dict[\"logits_matching_batchsize\"]\n",
        "    aug = conf_dict[\"aug\"]\n",
        "    compress = conf_dict[\"compress\"]\n",
        "    select = conf_dict[\"select\"]\n",
        "    algorithm = conf_dict[\"algorithm\"]\n",
        "\n",
        "    result_save_dir = conf_dict[\"result_save_dir\"]\n",
        "\n",
        "del conf_dict, conf_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqPxJvPfl5Ro"
      },
      "source": [
        "# Generate data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXyGLMyrl5Ro",
        "outputId": "dc314f40-479c-478d-91c9-c5ba1c198733"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_load_functions = {\n",
        "    \"MNIST\": load_MNIST_data,\n",
        "    \"FEMNIST\": load_FEMNIST_data,\n",
        "    \"CIFAR10\": load_CIFAR10_data,\n",
        "    \"CIFAR100\": load_CIFAR100_data,\n",
        "}\n",
        "\n",
        "\n",
        "X_train_public, y_train_public, X_test_public, y_test_public \\\n",
        "= data_load_functions[public_dataset_name](standarized = True, verbose = True)\n",
        "\n",
        "public_dataset = {\"X\": X_train_public, \"y\": y_train_public}\n",
        "\n",
        "X_train_private, y_train_private, X_test_private, y_test_private \\\n",
        "= data_load_functions[private_dataset_name](standarized = True, verbose = True)\n",
        "\n",
        "\n",
        "private_classes = np.unique(y_train_private)\n",
        "\n",
        "# X_train_private, y_train_private \\\n",
        "# = generate_partial_data(X = X_train_private, y= y_train_private,\n",
        "#                         class_in_use = private_classes,\n",
        "#                         verbose = True)\n",
        "# X_test_private, y_test_private \\\n",
        "# = generate_partial_data(X = X_test_private, y= y_test_private,\n",
        "#                         class_in_use = private_classes,\n",
        "#                         verbose = True)\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "#generate private data\n",
        "private_data, total_private_data\\\n",
        "=generate_bal_private_data(X_train_private, y_train_private,\n",
        "                            N_parties = N_parties,\n",
        "                            classes_in_use = private_classes,\n",
        "                            N_samples_per_class = N_samples_per_class,\n",
        "                            data_overlap = False)\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "# X_tmp, y_tmp = generate_partial_data(X = X_test_private, y= y_test_private,\n",
        "#                                         class_in_use = private_classes,\n",
        "#                                         verbose = True)\n",
        "\n",
        "for i in range(N_parties):\n",
        "    private_data[i]['y'] = tf.keras.utils.to_categorical(private_data[i]['y'], len(private_classes))\n",
        "y_test_private = tf.keras.utils.to_categorical(y_test_private, len(private_classes))\n",
        "\n",
        "private_test_data = {\"X\": X_test_private, \"y\": y_test_private}\n",
        "\n",
        "# del X_tmp, y_tmp\n",
        "\n",
        "parties = []\n",
        "if model_saved_dir is None:\n",
        "    for i, item in enumerate(model_config):\n",
        "        model_name = item[\"model_type\"]\n",
        "        model_params = item[\"params\"]\n",
        "        tmp = CANDIDATE_MODELS[model_name](n_classes=n_classes,\n",
        "                                            input_shape=(32,32,3),\n",
        "                                            **model_params)\n",
        "        print(\"model {0} : {1}\".format(i, model_saved_names[i]))\n",
        "        # print(tmp.summary())\n",
        "        parties.append(tmp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiIgM9crl5Ro"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB9wN8Vhl5Ro"
      },
      "outputs": [],
      "source": [
        "my_data_dir = '../data'\n",
        "if not os.path.exists(my_data_dir):\n",
        "    os.mkdir(my_data_dir)\n",
        "\n",
        "# create a directory for the private dataset\n",
        "dataset_dir = os.path.join(my_data_dir, private_dataset_name)\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.mkdir(dataset_dir)\n",
        "\n",
        "# create a directory for each client and save its private data\n",
        "for i, d in enumerate(private_data) :\n",
        "    client_dir = os.path.join(dataset_dir, str(i))\n",
        "    if not os.path.exists(client_dir):\n",
        "        os.mkdir(client_dir)\n",
        "    np.save(os.path.join(client_dir, 'X'), d['X'])\n",
        "    np.save(os.path.join(client_dir, 'y'), d['y'])\n",
        "\n",
        "# create a directory for the public dataset\n",
        "alignment_dir = os.path.join(dataset_dir, 'alignment')\n",
        "if not os.path.exists(alignment_dir):\n",
        "    os.mkdir(alignment_dir)\n",
        "\n",
        "# save the public data in files, one for each class.\n",
        "# The data is saved in class-separated files, so the labels are the file names.\n",
        "public_classes = np.unique(y_train_public)\n",
        "for c in public_classes:\n",
        "    X_c = X_train_public[np.where(y_train_public == c)[0]]\n",
        "    np.save(os.path.join(alignment_dir, 'X_align_{}'.format(c)), X_c)\n",
        "\n",
        "# make a directory for the test data\n",
        "# the test data is saved in class-separated files, so the labels are the file names.\n",
        "test_dir = os.path.join(my_data_dir, private_dataset_name, 'test')\n",
        "if not os.path.exists(test_dir):\n",
        "    os.mkdir(test_dir)\n",
        "for c in private_classes:\n",
        "    X_test_private_c = X_test_private[np.where(y_test_private == c)[0]]\n",
        "    np.save(os.path.join(test_dir, 'X_{}'.format(c)), X_test_private_c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XthwNDeeq5m5"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpjuTKUvl5Ro"
      },
      "outputs": [],
      "source": [
        "my_data_dir = '../data'\n",
        "dataset_name = 'CIFAR10'\n",
        "clients_data, alignment_data, test_data = load_ready_data(my_data_dir, dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fapsgm_mrj4O",
        "outputId": "837aaf9a-73c6-409f-e086-bfccdbfb708e"
      },
      "outputs": [],
      "source": [
        "len(clients_data[0]), clients_data[0][0].shape, len(alignment_data), alignment_data[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBpVPyhVl5Rp"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ajDZ_Bl5Rp",
        "outputId": "09ccc486-19c6-414b-d8c4-1d7efd3b6188"
      },
      "outputs": [],
      "source": [
        "new_total_private_data = {}\n",
        "new_total_private_data['X'] = np.concatenate([p[0] for p in clients_data ], axis = 0)\n",
        "new_total_private_data['y'] = np.concatenate([p[1] for p in clients_data ], axis = 0)\n",
        "\n",
        "new_total_private_data['X'].shape, new_total_private_data['y'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLe6ROfUl5Rp"
      },
      "outputs": [],
      "source": [
        "print(\"size of public data:\", size_of(public_dataset['X']))\n",
        "print(\"size of logits:\", size_of(public_dataset['y']))\n",
        "print(\"size of total private data:\", size_of(total_private_data['X']))\n",
        "print(\"size of private data:\", size_of(private_data[0]['X']))\n",
        "print(\"size of model:\", size_of(parties[0]))\n",
        "print(\"number of parties:\", len(parties))\n",
        "\n",
        "size_of(public_dataset['y']), size_of(parties[0]), len(parties), size_of(public_dataset['X'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCSnSeVOl5Rp"
      },
      "outputs": [],
      "source": [
        "input_shape = private_data[0][\"X\"].shape[1:]\n",
        "# [0.5483333468437195, 0.5421666502952576, 0.6263333559036255, 0.4596666693687439, 0.5808333158493042, 0.6393333077430725, 0.6313333511352539, 0.5663333535194397, 0.5171666741371155, 0.503333330154419]\n",
        "\n",
        "local_trials = []\n",
        "for i in range(len(private_data)):\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    item = model_config[0]\n",
        "    model_name = item[\"model_type\"]\n",
        "    model_params = item[\"params\"]\n",
        "    model_ub = CANDIDATE_MODELS[model_name](n_classes=n_classes,\n",
        "                                        input_shape=input_shape,\n",
        "                                        **model_params)\n",
        "    model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
        "                        loss = \"sparse_categorical_crossentropy\",\n",
        "                        metrics = [\"accuracy\"])\n",
        "    ub_history = model_ub.fit(private_data[i]['X'], private_data[i]['y'],\n",
        "                    batch_size = 30, epochs = 30, shuffle=True, verbose = True,\n",
        "                    validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                    callbacks=[EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=7, restore_best_weights=True)])\n",
        "\n",
        "    local_trials.append(ub_history.history[\"val_accuracy\"])\n",
        "    print(\"final accuracy:\", ub_history.history[\"val_accuracy\"][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN3jf-j0l5Rq"
      },
      "outputs": [],
      "source": [
        "\n",
        "central_trials = []\n",
        "for i in range(5) :\n",
        "    tf.keras.backend.clear_session()\n",
        "    input_shape = private_data[0][\"X\"].shape[1:]\n",
        "\n",
        "    cbs = [EarlyStopping(monitor=\"val_accuracy\", min_delta=0.001, patience=7, restore_best_weights=True)]\n",
        "    cbs = []\n",
        "\n",
        "    item = model_config[0]\n",
        "    model_name = item[\"model_type\"]\n",
        "    model_params = item[\"params\"]\n",
        "    model_ub = CANDIDATE_MODELS[model_name](n_classes=n_classes,\n",
        "                                        input_shape=input_shape,\n",
        "                                        **model_params)\n",
        "    model_ub.compile(optimizer=tf.keras.optimizers.Adam(lr = 1e-3),\n",
        "                        loss = \"sparse_categorical_crossentropy\",\n",
        "                        metrics = [\"accuracy\"])\n",
        "    print(\"shpae of private data:\", private_data[0][\"X\"].shape)\n",
        "    ub_history = model_ub.fit(new_total_private_data['X'], new_total_private_data['y'],\n",
        "                    batch_size = 30, epochs = 40, shuffle=True, verbose = True,\n",
        "                    validation_data = [private_test_data[\"X\"], private_test_data[\"y\"]],\n",
        "                    callbacks=[cbs])\n",
        "\n",
        "    central_trials.append(ub_history.history[\"val_accuracy\"])\n",
        "    print(\"final accuracy:\", ub_history.history[\"val_accuracy\"][-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yZ9mMQ9l5Rp"
      },
      "outputs": [],
      "source": [
        "local_accuracy = np.mean([acc[-1] for acc in local_trials])\n",
        "central_accuracy = np.mean([acc[-1] for acc in central_trials])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmbTXydGl5Rp",
        "outputId": "fb63cf0f-5a72-4ca2-8fe5-637a0048a55b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for the bar plot\n",
        "# accuracies = [0.5483333468437195, 0.5421666502952576, 0.6263333559036255, 0.4596666693687439, 0.5808333158493042, 0.6393333077430725, 0.6313333511352539, 0.5663333535194397, 0.5171666741371155, 0.503333330154419]\n",
        "accuracies = [0.011, 0.013, 0.010, 0.013, 0.013, 0.011, 0.012, 0.012, 0.010, 0.015]\n",
        "# accuracies = [acc[-1] for acc in local_accuracies]\n",
        "# Clients for the x-axis (assuming one accuracy value per client)\n",
        "clients = range(1, len(accuracies) + 1)\n",
        "\n",
        "# Create a figure and axes for the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "# Plot the bar chart with custom colors, edgecolor, and width\n",
        "bars = ax.bar(clients, accuracies, color='steelblue', edgecolor='black', width=0.5, label = 'Local Accuracy')\n",
        "\n",
        "# Add values on top of the bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.annotate(f'{height:.3f}', xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3),\n",
        "                textcoords=\"offset points\", ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Set x and y axis labels and title\n",
        "ax.set_xlabel('Clients', fontsize = 20)\n",
        "ax.set_ylabel('Final Accuracy', fontsize = 20)\n",
        "# ax.set_title('Accuracies of Clients\\' Local Training',  fontsize = 20)\n",
        "\n",
        "# Add a horizontal line at accuracy 70 to mark it as the central accuracy\n",
        "# central_avg_acc = np.mean([acc[-1] for acc in central_trials])\n",
        "central_avg_acc = 0.7\n",
        "central_avg_acc = 0.14\n",
        "ax.axhline(y=central_avg_acc, color='red', linestyle='--', label='Central Accuracy')\n",
        "\n",
        "# Add a horizontal line for the average accuracy local\n",
        "ax.axhline(y=sum(accuracies)/len(accuracies), color='green', linestyle='--', label='Average Local Accuracy')\n",
        "\n",
        "print(\"average:\", sum(accuracies)/len(accuracies))\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='y', linestyle='dotted')\n",
        "ax.tick_params(axis='both', labelsize=18)\n",
        "\n",
        "# Set the y-limit if needed\n",
        "ax.set_ylim([0, 0.15])\n",
        "# Adjust the layout to avoid cutting off labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add a legend with position right bottom\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Save the plot as a high-quality PDF\n",
        "plt.savefig('local_central_cifar.pdf', dpi=300)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y233lWsWl5Rq"
      },
      "outputs": [],
      "source": [
        "np.mean([acc[-1] for acc in central_trials]), [acc[-1] for acc in central_trials]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qxBud-vl5Rq"
      },
      "outputs": [],
      "source": [
        "np.mean(local_trials), np.std(local_trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLbSqLjdl5Rq"
      },
      "outputs": [],
      "source": [
        "np.mean(central_trials), np.std(central_trials), central_trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7egMILoHl5Rq"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
